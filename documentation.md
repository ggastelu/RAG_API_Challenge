# API de An√°lisis Sem√°ntico y RAG en art√≠culos cient√≠ficos de qu√≠mica

## Descripci√≥n General
Esta API permite realizar an√°lisis sem√°nticos avanzados y responder preguntas sobre art√≠culos cient√≠ficos,utilizando un flujo de generaci√≥n aumentada por recuperaci√≥n (RAG). Combina modelos de lenguaje de Cohere con b√∫squedas en bases de datos vectoriales (ChromaDB) para ofrecer respuestas precisas y contextualizadas basadas en documentos.

El sistema utiliza vectores embebidos para localizar informaci√≥n relevante sobre un determinado contenido.
Se encuentran en desarrollo herramientas para realizar b√∫squedas por DOI y autor.

## Estructura del Proyecto
El proyecto est√° organizado de la siguiente manera:
üìÇ project_root/
‚îú‚îÄ‚îÄ main.py # Archivo principal para arrancar la API 
‚îú‚îÄ‚îÄ üìÇ models/ 
|    ‚îî‚îÄ‚îÄ models.py # Configuraci√≥n del vectorstore y modelos 
‚îú‚îÄ‚îÄ üìÇ routers/ ‚îÇ 
|    ‚îî‚îÄ‚îÄ endpoints.py # Definici√≥n de los endpoints 
‚îú‚îÄ‚îÄ üìÇ utils/ 
‚îÇ   ‚îî‚îÄ‚îÄ utils.py # Funciones auxiliares y herramientas  
‚îî‚îÄ‚îÄ requirements.txt # Lista de dependencias

## Requisitos Previos
Para ejecutar esta API, necesitas instalar las siguientes dependencias. Estas est√°n enumeradas en el archivo `requirements.txt`.

### Dependencias Principales
- **uvicorn**: Servidor ASGI para ejecutar la API.
- **fastapi**: Framework para construir APIs web modernas y r√°pidas.
- **cohere**: Librer√≠a para interactuar con los modelos de lenguaje de Cohere.
- **python-dotenv**: Manejo de variables de entorno desde un archivo `.env`.
- **chromadb**: Base de datos vectorial para recuperaci√≥n de informaci√≥n.
- **langchain**: Framework para construir cadenas de procesamiento con LLMs.
- **langchain_chroma**: Conector para usar ChromaDB con LangChain.
- **langchain_cohere**: Conector para integrar Cohere con LangChain.

## Requisitos Adicionales
- Python: Aseg√∫rate de tener Python 3.9 o superior instalado.
- Acceso a Internet: Para interactuar con Cohere y descargar dependencias.

## Gu√≠a R√°pida
1. Clona este repositorio.
2. Instala las dependencias:
   ```bash
   pip install -r requirements.txt
3. Crea un archivo .env en el directorio ra√≠z para configurar las claves de acceso necesarias. 
    Ejemplo de archivo .env: 
    COHERE_API_KEY=<tu-api-key-de-cohere>

## Endpoints de la API

### 1. Subida de documentos XML

#### POST `/upload`

**Descripci√≥n**

Este endpoint permite subir un archivo XML, extraer su contenido, generar fragmentos (chunks) con metadatos, y almacenarlos en un diccionario interno para su posterior procesamiento.

**Par√°metros del cuerpo de la solicitud:**

- `file`: Archivo XML que contiene el documento a procesar. Debe cumplir con el formato `.xml`.

**Funcionamiento:**

1. **Validaci√≥n del archivo:** Verifica que el archivo tenga la extensi√≥n `.xml`. Si no cumple, retorna un error `400 Bad Request`.
2. **Procesamiento del contenido XML:** Convierte el contenido del archivo a un diccionario usando `xmltodict` y maneja cualquier error durante el proceso.
3. **Extracci√≥n de informaci√≥n:** Usa la funci√≥n `extract_information_XMLdict` para extraer datos como:
   - `title`: T√≠tulo del documento.
   - `doi`: DOI del documento.
   - `authors`: Lista de autores.
   - `sections`: Secciones del documento.
4. **Verificaci√≥n de duplicados:** Comprueba si el DOI ya est√° cargado en el diccionario interno `chunks_con_metadata`. Si ya existe, retorna un error `400 Bad Request`.
5. **Generaci√≥n de chunks:** Usa la funci√≥n `chunks_generation` para dividir las secciones en fragmentos manejables y a√±ade metadatos como `id`, `text`, `title`, `authors` y `doi`.
6. **Almacenamiento:** Guarda los fragmentos generados en el diccionario `chunks_con_metadata`.

**Respuesta exitosa (200 OK):**

```json
{
  "message": "Document uploaded successfully",
  "DOI": "10.1234/example.doi"
}
```

**Errores posibles:**

- 400 Bad Request:

    - Si el archivo no es un XML:
        ```json
        {
        "detail": "El archivo debe ser un XML."
        }
        ```
    - Si el DOI ya est√° cargado:
        ```json
        {
        "detail": "El DOI '10.1234/example.doi' ya est√° cargado pero no embebido."
        }
        ```
- 500 Internal Server Error:

    - Error interno al procesar el XML:
        ```json
        {
        "detail": "Error al procesar el XML: [descripci√≥n del error]"
        }
        ```
    - Error al extraer informaci√≥n del XML:
        ```json
        {
        "detail": "Error al extraer informaci√≥n del XML: [descripci√≥n del error]"
        }
        ```
    - Error al generar los chunks:
        ```json
        {
        "detail": "Error al generar chunks: [descripci√≥n del error]"
        }
        ```
    - Error inesperado:
        ```json
        {
        "detail": "Error interno en el servidor.",
        "traceback": "[pila de errores]"
        }
        ```
    
**Notas adicionales:**

Este endpoint no almacena los datos en una base de datos persistente. Los fragmentos se almacenan temporalmente en el diccionario chunks_con_metadata para procesamientos adicionales.
El diccionario chunks_con_metadata utiliza el DOI como clave √∫nica.

### 2. Embedding de documentos

#### POST `/embed`

**Descripci√≥n:**

Este endpoint genera embeddings para los **chunks** del documento especificado por el **DOI** y los a√±ade a la colecci√≥n de ChromaDB. Los embeddings generados se utilizan para realizar b√∫squedas de similitud posteriormente.

El proceso involucra los siguientes pasos:

    - Verificaci√≥n del DOI: Se verifica si el DOI est√° presente en el diccionario de datos cargados (chunks_con_metadata).
    - Preparaci√≥n de los Chunks y Metadatos: Los chunks de texto y sus metadatos (DOI, t√≠tulo y autores) son extra√≠dos.
    - Generaci√≥n de Embeddings: Los embeddings generados se a√±aden a la colecci√≥n de ChromaDB.
    - Limpieza: Los chunks procesados son eliminados del diccionario local para evitar duplicados en futuras solicitudes.

**Par√°metros del cuerpo de la solicitud:**

- **doi** (tipo: `str`): El **DOI** del documento para el cual se generar√°n los embeddings y se a√±adir√°n a la colecci√≥n.

**Funcionamiento:**

1. **Par√°metros de entrada:** Se detalla el par√°metro **DOI** que debe ser enviado en la solicitud.
2. **Respuesta:** Se describe la respuesta con un campo **message** que indica si los embeddings fueron generados y a√±adidos exitosamente.
3. **Excepciones:** Se describen las excepciones posibles, como si el **DOI** no se encuentra en los datos cargados o si hay errores en el procesamiento.
4. **Implementaci√≥n en el c√≥digo:** Se muestra c√≥mo se implementa el endpoint en FastAPI para generar los embeddings y agregarlos a la colecci√≥n de ChromaDB.

**Respuesta:**

- **message** (tipo: `str`): Mensaje indicando si los embeddings fueron generados y a√±adidos correctamente a la colecci√≥n.

**Ejemplo de solicitud:**

- **Request:**

        ```json
        {
        "doi": "10.1021/acs.jctc.8b00959"
        }
        ```

**Ejemplo de respuesta:**

- **Response:**

        ```json
        {
        "message": "Embeddings generados y a√±adidos con √©xito para el DOI 10.1021/acs.jctc.8b00959"
        }
        ```

**Modelos de datos utilizados:**

- **ChunkMetadata:** Representa la metadata y los chunks de un documento. Se utiliza para almacenar informaci√≥n sobre el contenido, t√≠tulo, autores, secci√≥n, y DOI.

**Errores posibles:**

- 404 - DOI no encontrado en los datos cargados: Si el DOI especificado no existe en los datos cargados (en el diccionario chunks_con_metadata).

- 500 - Los datos de chunks no est√°n en el formato esperado: Si los datos de los chunks no est√°n en el formato esperado (una lista de diccionarios).

- 500 - Error al acceder a las claves en los datos: Si ocurre un error al intentar acceder a las claves necesarias en los chunks.

- 500 - Error al agregar a la colecci√≥n: Si ocurre un error al intentar agregar los chunks y metadatos al vectorstore de ChromaDB.

**Consideraciones adicionales:**

- El **DOI** es un identificador √∫nico para los documentos, y este endpoint asume que cada **DOI** tiene un conjunto de **chunks** de texto que pueden ser procesados para generar embeddings.
- El c√≥digo maneja errores como la falta de un **DOI** en los datos, problemas con el formato de los **chunks**, o errores al intentar agregar los datos a la colecci√≥n de ChromaDB.

### 3. B√∫squeda en la base de datos

#### POST `/search`

**Descripci√≥n:**
Este endpoint realiza una b√∫squeda en la colecci√≥n de ChromaDB utilizando LangChain y devuelve los documentos m√°s relevantes junto con sus puntuaciones de similitud. 

La b√∫squeda se ejecuta en funci√≥n de la consulta proporcionada por el usuario, utilizando un modelo de similitud (por ejemplo, cosine) que compara los vectores de la consulta con los documentos almacenados en ChromaDB.

***Par√°metros del cuerpo de la solicitud:**

- **query** (tipo: `AskRequest`): 
  - **question** (tipo: `str`): La consulta de b√∫squeda que se utilizar√° para encontrar documentos relacionados.

**Funcionamiento:**

1. **Par√°metros de entrada:** Se detalla que la solicitud debe incluir un campo `question` con la consulta de b√∫squeda.
2. **Respuesta:** Se explica la estructura de los resultados, incluyendo los campos `doi`, `title`, `content_snippet` y `similarity_score`.
3. **Excepciones:** Se describe c√≥mo se manejan los errores (por ejemplo, cuando no se encuentran resultados o cuando ocurre un error del servidor).
4. **Implementaci√≥n en el c√≥digo:** Se muestra c√≥mo se implementa el endpoint en FastAPI para realizar la b√∫squeda y retornar los resultados.

**Respuesta:**

- **results** (tipo: `list`): Lista de resultados de b√∫squeda, cada uno con los siguientes campos:
  - **doi** (tipo: `str`): DOI del documento.
  - **title** (tipo: `str`): T√≠tulo del documento.
  - **content_snippet** (tipo: `str`): Fragmento de texto del documento relevante para la consulta.
  - **similarity_score** (tipo: `float`): Puntuaci√≥n de similitud entre el documento y la consulta.

**Ejemplo de solicitud:**

- **Request:**
        Modelo Utilizado:
            AskRequest: Solicitud que contiene la pregunta del usuario.

        ```json
        {
        "question": "Machine Learning en la qu√≠mica"
        }
        ```

- **Response:**
        Modelos Utilizados:
            SearchResult: Representa un resultado de b√∫squeda con su DOI, t√≠tulo, fragmento de contenido y puntuaci√≥n de similitud.
            SearchResponse: Respuesta que contiene una lista de SearchResult.

        ```json
        {
        "results": [
            {
            "doi": "10.1021/acs.chemrev.1c00033",
            "title": "Machine Learning for Chemical Reactions",
            "content_snippet": "use of machine learning. The combination of electronic structure theory, molecular dynamics, machine learning, and virtual reality brings this one step closer and will also have potentially far reachi",
            "similarity_score": 0.5680800080299377
            },
            {
            "doi": "10.1039/d2sc05089g",
            "title": "Predictive chemistry: machine learning for reaction deployment, reaction development, and reaction discovery",
            "content_snippet": "Up to this point, the focus of this review has been on ML applications involving known chemistry, i.e., interpolation based on existing data, which inherently implies that the prediction is constraine",
            "similarity_score": 0.6289628744125366
            },
            {
            "doi": "10.1021/acs.chemrev.1c00033",
            "title": "Machine Learning for Chemical Reactions",
            "content_snippet": "Machine learning (ML) techniques applied to chemical reactions have a long history. The present contribution discusses applications ranging from small molecule reaction dynamics to computational platf",
            "similarity_score": 0.6620815396308899
            },
            {
            "doi": "10.1039/d2sc05089g",
            "title": "Predictive chemistry: machine learning for reaction deployment, reaction development, and reaction discovery",
            "content_snippet": "Advances in the high-throughput generation and availability of chemical reaction data have spurred a rapidly growing interest in the intersection of machine learning and chemical synthesis.  Deep lear",
            "similarity_score": 0.6723558902740479
            },
            {
            "doi": "10.1021/acs.chemrev.1c00033",
            "title": "Machine Learning for Chemical Reactions",
            "content_snippet": "problems involving reactions in the gas phase, in solution, and in enzymes. Most problems concerning the representation of the underlying potential energy surfaces are excluded, as these are already w",
            "similarity_score": 0.6779579520225525
            }
        ]
        }
        ```

**Errores posibles:**

- 404 - No se encontraron resultados relevantes: Si no se encuentran documentos relevantes en la base de datos de ChromaDB para la consulta proporcionada.

- 500 - Error en el servidor: Si ocurre un error durante la ejecuci√≥n de la b√∫squeda o procesamiento de la consulta.

### 4. Pregunta a la base de datos

#### POST `/ask`

**Descripci√≥n:**
Este endpoint responde a una pregunta utilizando los resultados m√°s relevantes obtenidos desde **ChromaDB** y el modelo **Cohere**, con el contexto extra√≠do de art√≠culos cient√≠ficos. La respuesta se genera en base al contexto relevante de los documentos almacenados.

Utiliza la t√©cnica de RAG (Retrieval-Augmented Generation) para generar una respuesta basada en el contenido de los documentos relevantes encontrados. Los pasos detallados del proceso son:

    - B√∫squeda en ChromaDB: Se realiza una b√∫squeda en la colecci√≥n de ChromaDB utilizando la pregunta proporcionada.
    - Obtenci√≥n del contexto relevante: Los textos de los documentos m√°s relevantes son extra√≠dos y concatenados en un √∫nico bloque de contexto.
    - Verificaci√≥n de la existencia de DOIs: Se extraen los DOIs de los documentos relevantes, que se incluyen en la respuesta para proporcionar referencias a las fuentes.
    - Generaci√≥n de la respuesta: Si el contexto es adecuado, se utiliza el modelo Cohere para generar una respuesta. Si no, se devuelve una validaci√≥n indicando que no se pudo generar una respuesta.

**Par√°metros de entrada**

- **question** (tipo: `str`): La **pregunta** que se quiere hacer al sistema. El modelo buscar√° en ChromaDB los documentos m√°s relevantes para esta consulta.

**Respuesta:**

- **question** (tipo: `str`): La pregunta que se recibi√≥ en la solicitud.
- **answer** (tipo: `str`): La respuesta generada basada en los documentos relevantes encontrados en la b√∫squeda, o una validaci√≥n de que no se encontr√≥ un contexto relevante para la respuesta.

**Funcionamiento:**

- **Par√°metros de entrada:** Se detalla el par√°metro question que debe ser enviado en la solicitud.
- **Respuesta:** La respuesta contiene la pregunta que fue enviada y la respuesta generada por el modelo Cohere, basada en los documentos relevantes obtenidos.
- **Excepciones:** Se describen las excepciones posibles, como si no se encontraron resultados relevantes en la b√∫squeda o si ocurre un error en el proceso de generaci√≥n de la respuesta.
- **Implementaci√≥n en el c√≥digo:** Se proporciona el c√≥digo de FastAPI para este endpoint, que realiza la b√∫squeda y genera la respuesta utilizando el contexto relevante de los documentos.

**Ejemplo de solicitud:**

- **Request:**
        Modelo Utilizado:
            AskRequest: Solicitud que contiene la pregunta del usuario.

        ```json
        {
        "question": "¬øC√≥mo se puede usar 'Machine Learning' en la qu√≠mica?"
        }
        ```

- **Response:**
        Modelo Utilizado:
            AskResponse: Respuesta que contiene la pregunta y la respuesta generada.

        ```json
        {
        "question": "como se puede usar machine learning en la qu√≠mica?",
        "answer": "Las t√©cnicas de aprendizaje autom√°tico (machine learning) en qu√≠mica tienen un amplio rango de aplicaciones, desde la din√°mica de reacciones de peque√±as mol√©culas hasta plataformas computacionales para la planificaci√≥n de reacciones. Estas t√©cnicas son especialmente √∫tiles para problemas que involucran tanto computaci√≥n como experimentos, permitiendo el desarrollo de modelos consistentes con el conocimiento experimental y abordando problemas que son intratables con m√©todos convencionales. La combinaci√≥n de aprendizaje autom√°tico, experimentaci√≥n y simulaci√≥n puede optimizar sistemas de reacciones qu√≠micas para tareas espec√≠ficas, como maximizar rendimientos o minimizar el uso de disolventes problem√°ticos.\n\nBibliograf√≠a: 10.1039/d2sc05089g, 10.1021/acs.chemrev.1c00033"
        }
        ```

**Errores posibles:**

- 404 - No se encontraron resultados relevantes: Si no se encuentran documentos relevantes en la base de datos de ChromaDB que se ajusten a la pregunta.

- 500 - Error al generar la respuesta: Si ocurre un error al procesar la pregunta o generar la respuesta basada en el contexto.

### 5. Listado de DOIs de la base de datos

#### GET `/get_all_dois`

**Descripci√≥n:**

Este endpoint recupera todos los documentos almacenados en la colecci√≥n de **ChromaDB** y extrae el valor del **DOI** de los metadatos de cada documento. Los DOIs se almacenan en un set para asegurar que no haya duplicados y luego se devuelve como una lista. Los pasos detallados del proceso son:

    - Recuperaci√≥n de documentos: Se accede a la colecci√≥n de ChromaDB y se obtienen todos los documentos almacenados.
    - Extracci√≥n de DOIs: Se extraen los DOIs de los metadatos de los documentos.
    - Eliminaci√≥n de duplicados: Se utiliza un set para eliminar duplicados y asegurar que cada DOI aparezca solo una vez.
    - Devoluci√≥n de DOIs: Los DOIs √∫nicos se devuelven en una lista como respuesta.

**Respuesta:**

- **dois** (tipo: `list`): Lista de **DOIs** √∫nicos extra√≠dos de los metadatos de los documentos en la colecci√≥n.

**Funcionamiento:**

- **Recuperaci√≥n de documentos:** Se usa vectorstore._collection.get() para acceder a los documentos almacenados en la colecci√≥n de ChromaDB.
- **Extracci√≥n de DOIs:** Se extraen los DOIs de los metadatos de cada documento y se almacenan en un set para eliminar duplicados.
- **Devoluci√≥n de la respuesta:** Se devuelve la lista de DOIs √∫nicos en el formato adecuado.

**Ejemplo de solicitud:**

- **Request:**

        ```http
        GET /get_all_dois
        ```

- **Response:**

        ```json
        {
        "dois": [
            "10.1021/acs.jctc.8b00959",
            "10.1038/s41586-020-2015-2",
            "10.1126/science.abc123"
        ]
        }
        ```


### 6. Pregunta a la base de datos por herramientas

#### POST `/embed`

**Descripci√≥n:**## Endpoint: `POST /ask_tools`

**Descripci√≥n:**
Este endpoint est√° actualmente en construcci√≥n. Se proporcionar√° m√°s informaci√≥n sobre su funcionamiento pr√≥ximamente.

**Estado:**

En construcci√≥n

---

**Notas:**
- **Objetivo:** Proveer una funci√≥n para poder obtener distintas respuestas del modelo seg√∫n la pregunta que se realice. Por ejemplo, que sea capaz de identificar un DOI, buscar contexto en la base de ChromaDB y devolver informaci√≥n.

### Modelos de Datos

#### 1. ChunkMetadata
Representa la metadata y los chunks de un documento. Se utiliza para almacenar informaci√≥n sobre el contenido, t√≠tulo, autores, secci√≥n, y DOI.

class ChunkMetadata(BaseModel):
    text: str  # Texto del chunk
    title: str  # T√≠tulo del documento
    authors: str  # Autores del documento
    section_title: str  # T√≠tulo de la secci√≥n dentro del documento
    doi: str  # DOI (identificador √∫nico del documento)

#### 2. AskRequest
Modelo de solicitud para enviar una pregunta al sistema. Contiene un campo de tipo str para la pregunta.

class AskRequest(BaseModel):
    question: str  # Pregunta a responder

#### 3. SearchResult
Representa un resultado de b√∫squeda, incluyendo el DOI, el t√≠tulo, un fragmento del contenido relevante, y la puntuaci√≥n de similitud.

class SearchResult(BaseModel):
    doi: str  # Identificador √∫nico del documento
    title: str  # T√≠tulo del documento
    content_snippet: str  # Fragmento relevante del contenido
    similarity_score: float  # Puntuaci√≥n de relevancia (entre 0 y 1)

#### 4. SearchResponse
Modelo de respuesta para una b√∫squeda. Contiene una lista de SearchResult que representan los documentos m√°s relevantes encontrados.

class SearchResponse(BaseModel):
    results: list[SearchResult]  # Lista de documentos relevantes

#### 5. AskResponse
Modelo de respuesta a una consulta. Contiene la pregunta y la respuesta generada por el modelo.

class AskResponse(BaseModel):
    question: str  # La pregunta realizada
    answer: str  # Respuesta generada por el modelo

## L√≥gica de Modelos de Lenguaje

### Funci√≥n: `RAG_context`

#### Descripci√≥n
Verifica si el contexto contiene suficiente informaci√≥n para responder a una pregunta espec√≠fica, utilizando el modelo Cohere para tomar una decisi√≥n.

#### Par√°metros de Entrada
| Nombre     | Tipo   | Descripci√≥n                                                                 |
|------------|--------|-----------------------------------------------------------------------------|
| `context`  | `str`  | Informaci√≥n relevante obtenida de documentos cient√≠ficos o bases de datos. |
| `query`    | `str`  | La pregunta formulada por el usuario.                                       |

#### Retorno
- `str`: Una respuesta categ√≥rica:
  - `"Si"`: El contexto es suficiente para responder la pregunta.
  - `"No encontr√© informaci√≥n relevante en los trabajos disponibles."`: No hay suficiente informaci√≥n en el contexto.

#### Implementaci√≥n
```python
def RAG_context(context: str, query: str):
    #Conexi√≥n con Cohere para chequear la pregunta con el contexto:
    #system_request
    system_message = f"""
    Debes decidir si puedes responder a la pregunta, utilizando las posibles respuestas.
    Lo √∫nico que sabes es la siguiente informaci√≥n:

    Informaci√≥n relevante:
    {context}

    Pregunta: {query}
    
    Posibles respuestas:
        "Si"
        "No encontr√© informaci√≥n relevante en los trabajos disponibles." 
    """
    
    # user request
    user_message = f"""Comprueba si tienes la informaci√≥n necesaria para responder.
    Si la tienes, responde: Si.
    Si no la tienes, solo responde: "No encontr√© informaci√≥n relevante en los trabajos disponibles."
    """

    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": user_message},
    ]

    #Consulta al modelo
    response = co.chat(
        model="command-r-plus-08-2024", #utilizamos el modelo m√°s actual para obtener mejores respuestas
        messages=messages,
        seed=42 #agregamos semilla para disminuir aleatoriedad en las respuestas
    )

    model_answer = response.message.content[0].text
    return model_answer
    ```

#### Ejemplo de uso

contexto = "Este es el contexto relevante sobre machine learning y qu√≠mica en la base de datos."
pregunta = "¬øC√≥mo se aplica el machine learning a la qu√≠mica?"
respuesta = RAG_context(contexto, pregunta)
print(respuesta)
# Output: "Si" o "No encontr√© informaci√≥n relevante en los trabajos disponibles."

### Funci√≥n: `RAG_answer`

#### Descripci√≥n
Genera una respuesta detallada y t√©cnica en espa√±ol a una pregunta espec√≠fica utilizando un contexto relevante y citando bibliograf√≠a.

#### Par√°metros de Entrada
| Nombre      | Tipo   | Descripci√≥n                                                                 |
|-------------|--------|-----------------------------------------------------------------------------|
| `context`   | `str`  | Informaci√≥n relevante obtenida de documentos cient√≠ficos o bases de datos. |
| `dois_str`  | `str`  | Lista de identificadores DOI como referencia bibliogr√°fica.                 |
| `query`     | `str`  | La pregunta formulada por el usuario.                                       |

#### Retorno
- `str`: Una respuesta generada:
  - Responde la pregunta utilizando el contexto y mencionando la bibliograf√≠a al final.
  - Si no hay informaci√≥n suficiente, devuelve: `"No encontr√© informaci√≥n relevante en los trabajos disponibles."`

#### Implementaci√≥n
```python
def RAG_answer(context: str, dois_str: str, query: str):
    #Conexi√≥n con Cohere para responder a la pregunta con el contexto:
    #system_request
    system_message = f"""
    Eres un experto en qu√≠mica que solo habla espa√±ol. 
    Responde con lenguaje t√©cnico y certero.
    Usa solamente la informaci√≥n proporcionada a continuaci√≥n para responder la 
    pregunta de forma clara:

    Informaci√≥n relevante:
    {context}

    Pregunta: {query}
    Bibliograf√≠a: {dois_str}

    Si no tienes la informaci√≥n en informaci√≥n relevante, responde: "No encontr√© informaci√≥n relevante en los trabajos disponibles."
    """
    
    # user request
    user_message = f"""Comprueba si tienes la informaci√≥n necesaria para responder.
    Si la tienes, respondeme en 3 oraciones. Menciona la bibliograf√≠a al final.
    Si no la tienes, solo responde: "No encontr√© informaci√≥n relevante en los trabajos disponibles."
    """

    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": user_message},
    ]

    #Consulta al modelo
    response = co.chat(
        model="command-r-plus-08-2024", #utilizamos el modelo m√°s actual para obtener mejores respuestas
        messages=messages,
        seed=42 #agregamos semilla para disminuir aleatoriedad en las respuestas
    )

    model_answer = response.message.content[0].text
    return model_answer
    ```

#### Ejemplo de uso
contexto = "Aqu√≠ est√° el contexto relevante sobre compuestos qu√≠micos y su uso, en la base de datos."
dois = "10.1021/acs.jctc.8b00959, 10.1016/j.cplett.2023.139865"
pregunta = "¬øC√≥mo se pueden aplicar estos compuestos en reacciones catal√≠ticas?"
respuesta = RAG_answer(contexto, dois, pregunta)
print(respuesta)
# Output: Respuesta t√©cnica en espa√±ol con cita de DOI.

### Funciones en construcci√≥n

Varias funciones se encuentran en construcci√≥n para el endpoint POST/ask_tool

- determine_tool: un modelo de lenguaje determina qu√© herramienta debe usar en funci√≥n de la consulta.
- search_by_doi: herramienta para buscar todos los documentos con determinado DOI en metadata.
- search_by_author: herramiento para buscar todos los documentos de determinado autor.
- search_by_content: herramienta para responder seg√∫n contexto encontrado por similitud (reemplazo actual post/ask)

## Funciones auxiliares

### Funci√≥n Auxiliar: `extract_information_XMLdict`

#### Descripci√≥n
Procesa un archivo XML que contiene informaci√≥n estructurada de un art√≠culo cient√≠fico. Extrae el t√≠tulo, DOI, autores, abstract y el cuerpo del art√≠culo con sus respectivas secciones.

#### Par√°metros de Entrada
| Nombre         | Tipo  | Descripci√≥n                                                   |
|----------------|-------|---------------------------------------------------------------|
| `file_content` | `dict` | Contenido del archivo PDF en formato diccionario (sin uso directo en esta funci√≥n). |
| `xml_dict`     | `dict` | Diccionario que representa el contenido del archivo XML.      |

#### Retorno
- `title` (`str`): T√≠tulo del art√≠culo.
- `doi` (`str` o `None`): DOI del art√≠culo, si est√° disponible.
- `authors` (`list[str]`): Lista de nombres completos de los autores.
- `sections` (`list[dict]`): Lista de secciones con t√≠tulos y contenido:
  - `section_title`: T√≠tulo de la secci√≥n.
  - `section_content`: Contenido textual de la secci√≥n.

#### Implementaci√≥n
```python
def extract_information_XMLdict(file_content: dict, xml_dict):
    """
    Procesa un archivo XML de un art√≠culo cient√≠fico para extraer el cuerpo y metadata.
    Guarda metadata del art√≠culo.
    :param file_content: Contenido del archivo PDF en bytes.
    :param xml_dict: Diccionario que contiene el contenido del archivo XML.
    :return: T√≠tulo, DOI, lista de autores y secciones del art√≠culo.
    """
    # Extraer t√≠tulo
    title = "Sin t√≠tulo"
    try:
        if isinstance(xml_dict, dict):
            title = xml_dict.get("TEI", {}).get("teiHeader", {}).get("fileDesc", {}).get("titleStmt", {}).get("title", {}).get("#text", "Sin t√≠tulo")
    except Exception as e:
        print(f"Error al extraer t√≠tulo: {e}")
    
    # Extraer DOI
    doi = None
    try:
        biblStruct = xml_dict.get("TEI", {}).get("teiHeader", {}).get("fileDesc", {}).get("sourceDesc", {}).get("biblStruct", {})
        if isinstance(biblStruct, dict):
            idno_list = biblStruct.get("idno", [])
            for idno in idno_list:
                if isinstance(idno, dict) and idno.get("@type") == "DOI":
                    doi = idno.get("#text", None)
                    break
    except Exception as e:
        print(f"Error al extraer DOI: {e}")

    # Extraer autores
    authors = []
    try:
        authors_section = xml_dict.get("TEI", {}).get("teiHeader", {}).get("fileDesc", {}).get("sourceDesc", {}).get("biblStruct", {}).get("analytic", {}).get("author", [])
        if isinstance(authors_section, list):
            for author in authors_section:
                persName = author.get("persName", {})
                forename = ""
                surname = ""
                if persName:
                    if isinstance(persName.get("forename", []), list):
                        for name in persName["forename"]:
                            forename += name.get("#text", "") + " "
                    else:
                        forename = persName.get("forename", {}).get("#text", "")
                    surname = persName.get("surname", "")
                if forename or surname:
                    authors.append(f"{forename.strip()} {surname}".strip())
        elif isinstance(authors_section, dict):
            persName = authors_section.get("persName", {})
            forename = persName.get("forename", {}).get("#text", "")
            surname = persName.get("surname", "")
            if forename or surname:
                authors.append(f"{forename} {surname}")
    except Exception as e:
        print(f"Error al extraer autores: {e}")

    # Extraer abstract
    abstract = "Sin abstract"
    try:
        if isinstance(xml_dict, dict):
            abstract = xml_dict.get("TEI", {}).get("teiHeader", {}).get("profileDesc", {}).get("abstract", {}).get("div", {}).get("p", "Sin abstract")
    except Exception as e:
        print(f"Error al extraer abstract: {e}")

    # Filtrar cuerpo (body) y mantener secciones diferenciadas
    sections = []
    try:
        body = xml_dict.get("TEI", {}).get("text", {}).get("body", {}).get("div", [])
        if isinstance(body, list):
            for section in body:
                section_title = section.get("head", "Sin t√≠tulo de secci√≥n")
                section_content = section.get("p", "Sin contenido")
                if isinstance(section_content, list):
                    section_content = " ".join([p.get("#text", "") for p in section_content if isinstance(p, dict)])
                elif isinstance(section_content, dict):
                    section_content = section_content.get("#text", section_content)
                sections.append({"section_title": section_title, "section_content": section_content})
        else:
            sections.append({"section_title": "Sin t√≠tulo de secci√≥n", "section_content": body.get("p", "Sin contenido")})
    except Exception as e:
        print(f"Error al extraer secciones: {e}")

    sections.append({"section_title": "Abstract", "section_content": abstract})
    
    return title, doi, authors, sections
```

#### Ejemplo de uso

Supongamos que tenemos un archivo XML convertido en un diccionario.

``` python
xml_data = {
    "TEI": {
        "teiHeader": {
            "fileDesc": {
                "titleStmt": {"title": {"#text": "T√≠tulo del Art√≠culo"}},
                "sourceDesc": {"biblStruct": {"idno": [{"@type": "DOI", "#text": "10.1234/example"}]}}
            },
            "profileDesc": {"abstract": {"div": {"p": "Este es el abstract."}}}
        },
        "text": {"body": {"div": [{"head": "Introducci√≥n", "p": "Contenido de la introducci√≥n"}]}}
    }
}

titulo, doi, autores, secciones = extract_information_XMLdict({}, xml_data)
print(f"T√≠tulo: {titulo}")
print(f"DOI: {doi}")
print(f"Autores: {autores}")
print(f"Secciones: {secciones}")
```

### Funci√≥n Auxiliar: `chunks_generation`

#### Descripci√≥n
Toma la informaci√≥n estructurada de un art√≠culo cient√≠fico, como el t√≠tulo, DOI, autores y secciones, y divide el contenido de las secciones en fragmentos (chunks). A cada fragmento se le agrega metadata relevante, como el t√≠tulo del art√≠culo, autores y DOI.

#### Par√°metros de Entrada
| Nombre        | Tipo          | Descripci√≥n                                           |
|---------------|---------------|-------------------------------------------------------|
| `title`       | `str`         | T√≠tulo del art√≠culo cient√≠fico.                      |
| `doi`         | `str` o `None`| DOI del art√≠culo, si est√° disponible.                |
| `authors`     | `list[str]`   | Lista de nombres completos de los autores.           |
| `sections`    | `list[dict]`  | Lista de secciones con t√≠tulo y contenido.           |

#### Retorno
- `list[dict]`: Lista de fragmentos (chunks) con su contenido y metadatos asociados. Cada fragmento es un diccionario que contiene:
  - `text`: Contenido del fragmento.
  - `title`: T√≠tulo del art√≠culo.
  - `authors`: Lista de autores.
  - `doi`: DOI del art√≠culo.

#### Implementaci√≥n
```python
def chunks_generation(title, doi, authors, sections) -> list[dict]:
    """
    Toma la informaci√≥n extra√≠da del XML de un art√≠culo cient√≠fico y divide las secciones en chunks.
    Guarda metadata del art√≠culo: t√≠tulo, doi, autores, abstract y t√≠tulo de secci√≥n.
    :param title: T√≠tulo del art√≠culo.
    :param doi: DOI del art√≠culo.
    :param authors: Lista de autores del art√≠culo.
    :param sections: Lista de secciones del art√≠culo, cada una con t√≠tulo y contenido.
    :return: Lista de historias con t√≠tulo y sus respectivos chunks.
    """
    # Configura el divisor de texto
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,  # Tama√±o de cada fragmento
        chunk_overlap=30  # Superposici√≥n entre fragmentos
    )

    # Lista para almacenar los fragmentos con metadatos
    chunks_con_metadata = []

    # Itera sobre las secciones para dividir el contenido y agregar los metadatos
    for section in sections:
        section_title = section["section_title"]
        section_content = section["section_content"]
        
        # Divide el texto en fragmentos
        chunks = text_splitter.split_text(section_content)
        
        # Agrega metadatos a cada fragmento
        for chunk in chunks:
            chunks_con_metadata.append({
                "text": chunk,
                "title": title,
                "authors": authors,
                "doi": doi
            })

    return chunks_con_metadata
```

#### Ejemplo de uso

**Datos de entrada simulados**
title = "Ejemplo de T√≠tulo"
doi = "10.1234/example"
authors = ["Autor Uno", "Autor Dos"]
sections = [
    {"section_title": "Introducci√≥n", "section_content": "Contenido de la introducci√≥n. Es algo extenso para demostrar la divisi√≥n."},
    {"section_title": "Resultados", "section_content": "Aqu√≠ se muestran los resultados obtenidos."}
]

**Generar chunks**
chunks = chunks_generation(title, doi, authors, sections)

**Mostrar los chunks generados**
for chunk in chunks:
    print(f"Texto: {chunk['text']}")
    print(f"T√≠tulo: {chunk['title']}")
    print(f"Autores: {chunk['authors']}")
    print(f"DOI: {chunk['doi']}")
    print("---")

#### Notas
La funci√≥n utiliza RecursiveCharacterTextSplitter para dividir el contenido en fragmentos manteniendo un tama√±o fijo y cierta superposici√≥n.
Los metadatos incluidos en cada fragmento permiten rastrear el contexto del art√≠culo y facilitar el an√°lisis posterior.

### Funciones auxiliares en construcci√≥n

- extract_doi_from_query: extrae DOI de la solicitud del usuario para luego usar la herramienta search_by_doi. 
- extract_author_from_query: extrae nombre de autor de la solicitud del usuario para luego usar la herramienta search_by_author.